import rclpy  # ROS2 Python í´ë¼ì´ì–¸íŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬
from rclpy.node import Node  # ROS2 ë…¸ë“œ ë² ì´ìŠ¤ í´ëž˜ìŠ¤
from rclpy.executors import MultiThreadedExecutor  # ë©€í‹°ìŠ¤ë ˆë“œ ì‹¤í–‰ê¸°
from rclpy.qos import qos_profile_sensor_data
from sensor_msgs.msg import Image, CameraInfo  # ROS2 ì´ë¯¸ì§€ ë©”ì‹œì§€ íƒ€ìž…
from cv_bridge import CvBridge  # ROS ì´ë¯¸ì§€ :ì–‘ë°©í–¥_í™”ì‚´í‘œ: OpenCV ë³€í™˜ ë¸Œë¦¬ì§€
import cv2  # OpenCV ë¼ì´ë¸ŒëŸ¬ë¦¬
import numpy as np  # ìˆ˜ì¹˜ ì—°ì‚° ë¼ì´ë¸ŒëŸ¬ë¦¬
import math  # ìˆ˜í•™ í•¨ìˆ˜
import os  # ìš´ì˜ì²´ì œ ì¸í„°íŽ˜ì´ìŠ¤
import sys  # ì‹œìŠ¤í…œ ìƒí˜¸ìž‘ìš© 
import threading  # íŒŒì´ì¬ ìŠ¤ë ˆë”©
from ultralytics import YOLO  # YOLO ê°ì²´ ê°ì§€ ëª¨ë¸
from geometry_msgs.msg import PointStamped
import tf2_ros
import tf2_geometry_msgs
import rclpy.duration
from visualization_msgs.msg import Marker


# ================================
# ì„¤ì • ìƒìˆ˜
# ================================
MODEL_PATH = '/home/moonseungyeon/Downloads/11n_100picpt.pt'      # YOLO ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
RGB_TOPIC = '/robot2/oakd/rgb/preview/image_raw'       # RGB ì´ë¯¸ì§€ í† í”½
DEPTH_TOPIC = '/robot2/oakd/stereo/image_raw'
CAMERA_INFO_TOPIC = '/robot2/oakd/stereo/camera_info'
TARGET_CLASS_ID = 0                                    # ê´€ì‹¬ ê°ì²´ í´ëž˜ìŠ¤ ID (0=ìžë™ì°¨)
NORMALIZE_DEPTH_RANGE = 3.0                            # ê¹Šì´ ì •ê·œí™” ë²”ìœ„ (m)
INTRUSION_THRESHOLD = 0.10                             # ì¹¨ë²” íŒë‹¨ ìž„ê³„ì¹˜ (10%)
BOX_PLUS = 25
TARGET_CLASS_ID = 0
NORMALIZE_DEPTH_RANGE = 3.0  # meters

class YoloDepthGreenDetector(Node):
    def __init__(self):
        super().__init__('yolo_depth_green_detector')
        # ëª¨ë¸ íŒŒì¼ í™•ì¸
        if not os.path.exists(MODEL_PATH):
            self.get_logger().error(f"ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}")
            sys.exit(1)
        # YOLO ë¡œë“œ
        self.model = YOLO(MODEL_PATH)
        self.class_names = getattr(self.model, 'names', [])
        # CvBridge ì´ˆê¸°í™”
        self.bridge = CvBridge()
        # í† í”½ êµ¬ë…
        self.rgb_sub = self.create_subscription(Image, RGB_TOPIC, self.rgb_callback, 1)
        self.depth_sub = self.create_subscription(Image, DEPTH_TOPIC, self.depth_callback, 1)
        self.camera_info_sub = self.create_subscription(CameraInfo, CAMERA_INFO_TOPIC, self.camera_info_callback, 1)
        # ì´ë¯¸ì§€ ë²„í¼ ë° ë½
        self.latest_rgb = None
        self.latest_depth = None
        self.lock = threading.Lock()
        self.should_shutdown = False
        self.crop_y_point = 150
        # TF2 ë²„í¼ì™€ ë¦¬ìŠ¤ë„ˆ
        self.tf_buffer = tf2_ros.Buffer()
        self.tf_listener = tf2_ros.TransformListener(self.tf_buffer, self)
        self.marker_pub = self.create_publisher(Marker, 'detected_objects_marker', 10)
        self.marker_id = 0
        # í¼ë¸”ë¦¬ì…” ì¶”ê°€
        self.coord_pub = self.create_publisher(PointStamped, 'detected_object_position', 10)



    def camera_info_callback(self, msg: CameraInfo):
        self.fx = msg.k[0]
        self.fy = msg.k[4]
        self.cx = msg.k[2]
        self.cy = msg.k[5]
        self.get_logger().info(f":ë Œì¹˜: CameraInfo ìˆ˜ì‹ ë¨: fx={self.fx:.2f}, fy={self.fy:.2f}, cx={self.cx:.2f}, cy={self.cy:.2f}")
        self.camera_frame_id = msg.header.frame_id


    def depth_callback(self, msg):
        """Depth ì´ë¯¸ì§€ ì½œë°±"""
        try:
            depth = self.bridge.imgmsg_to_cv2(msg, desired_encoding='passthrough')
            with self.lock:
                self.latest_depth = depth
        except Exception as e:
            self.get_logger().warn(f"Depth ë³€í™˜ ì˜¤ë¥˜: {e}")


    def rgb_callback(self, msg):
        """RGB ì´ë¯¸ì§€ ì½œë°±"""
        try:
            img = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')
            with self.lock:
                # depth ë³µì‚¬
                self.latest_depth = self.latest_depth.copy() if self.latest_depth is not None else None
            self.latest_rgb = img
        except Exception as e:
            self.get_logger().warn(f"RGB ë³€í™˜ ì˜¤ë¥˜: {e}")
    

    def crop_image_bottom(self,img,a,b):
        # ì´ë¯¸ì§€ í¬ê¸° í™•ì¸ (360x360ì¸ì§€ í™•ì¸)
        if img.shape[:2] != (b, a):
            print(f"ê²½ê³ : ì´ë¯¸ì§€ í¬ê¸°ê°€ {img.shape[:2]}ìž˜ëª» ë“¤ì–´ ì™”ìŠµë‹ˆë‹¤.")
        # yì  ì•„ëž˜ ë¶€ë¶„ë§Œ ìžë¥´ê¸°
        cropped_img = img[self.crop_y_point:b, 0:b]
        return cropped_img
    

    def coor_correction(self,x,y,a,b,c,d):
        coor_ratio=d/b
        coor_add=(c-coor_ratio*a)/2
        return int(coor_ratio*x+coor_add),int(coor_ratio*y+(self.crop_y_point/2))
    

    def make_square_image(self, img):

        # ìœ„ì•„ëž˜ ë¹ˆ ê³µê°„ ì¶”ê°€ (ì´ ë†’ì´ 360pxë¡œ ë§žì¶¤)
        top_padding = (self.crop_y_point) // 2  # ìœ„ìª½ íŒ¨ë”©
        bottom_padding = (self.crop_y_point) // 2  # ì•„ëž˜ìª½ íŒ¨ë”©
        top_pad = np.ones((top_padding, img.shape[1], 3), dtype=np.uint8)* 255  # ê²€ì •ìƒ‰
        bottom_pad = np.ones((bottom_padding, img.shape[1], 3), dtype=np.uint8)* 255  # ê²€ì •ìƒ‰
        # ì„¸ë¡œë¡œ ìŒ“ì•„ì„œ 360x360 ì´ë¯¸ì§€ ìƒì„±
        result = np.vstack((top_pad, img, bottom_pad))
        return result
    
    def publish_marker(self, x, y, z):
        marker = Marker()
        marker.header.frame_id = 'map'
        marker.header.stamp = self.get_clock().now().to_msg()
        marker.ns = 'detected_objects'
        marker.id = self.marker_id
        self.marker_id += 1
        marker.type = Marker.SPHERE
        marker.action = Marker.ADD
        marker.pose.position.x = x
        marker.pose.position.y = y
        marker.pose.position.z = z
        marker.pose.orientation.w = 1.0
        marker.scale.x = marker.scale.y = marker.scale.z = 0.25
        marker.color.r = 1.0
        marker.color.g = 1.0
        marker.color.b = 0.0
        marker.color.a = 1.0
        marker.lifetime.sec = 3
        self.marker_pub.publish(marker)


    def process_and_show(self):
        """ë„ë¡œ ë§ˆìŠ¤í¬ + YOLO ê°ì²´ ê²€ì¶œ + ì¹¨ë²” íŒë‹¨ + Depth ì‹œê°í™”"""
        with self.lock:
            rgb_img = self.latest_rgb.copy() if self.latest_rgb is not None else None
            depth_img = self.latest_depth.copy() if self.latest_depth is not None else None
        if (rgb_img is None)|(depth_img is None):
            return
        #rgb_img=cv2.resize(rgb_img,(720,720))
        # :ì¼: ì´ˆë¡ìƒ‰ ë„ë¡œ ì˜ì—­ ë§ˆìŠ¤í¬ ìƒì„± (HSV)
        b,a=rgb_img.shape[:2]
        d,c=depth_img.shape[:2]
        rgb_img = self.crop_image_bottom(rgb_img,a,b)
        rgb_img = self.make_square_image(rgb_img)

        hsv = cv2.cvtColor(rgb_img, cv2.COLOR_BGR2HSV)
        lower_green = np.array([40, 40, 64])
        upper_green = np.array([80, 255, 255])
        green_mask = cv2.inRange(hsv, lower_green, upper_green)
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))
        green_mask = cv2.morphologyEx(green_mask, cv2.MORPH_OPEN, kernel)
        green_mask = cv2.morphologyEx(green_mask, cv2.MORPH_CLOSE, kernel)
        overlay = rgb_img.copy()
        overlay[green_mask>0] = (0,0,255)
        cv2.addWeighted(overlay, 0.3, rgb_img, 0.7, 0, rgb_img)
        # :ë‘˜: YOLO ê²€ì¶œ
        results = self.model(rgb_img, stream=True, conf=0.7)
        object_count = 0
        for r in results:
            for box in r.boxes:
                cls_id = int(box.cls[0])
                if cls_id != TARGET_CLASS_ID:
                    continue
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                cx, cy = self.coor_correction((x1 + x2) // 2, (y1 + y2) // 2,a,b,c,d)
                #cx, cy = (x1 + x2) // 2, (y1 + y2) // 2
                label = self.class_names[cls_id] if cls_id < len(self.class_names) else f"class_{cls_id}"
                conf = math.ceil(box.conf[0] * 100) / 100
                # :ì…‹: ë„ë¡œ ì˜ì—­ ì¹¨ë²” íŒë‹¨ (ë°•ìŠ¤ ë‚´ ì´ˆë¡ìƒ‰ ë§ˆìŠ¤í¬ ë¹„ìœ¨)
                roi_mask = green_mask[y1+int((y2-y1)*6/10):y2+BOX_PLUS, x1-BOX_PLUS:x2+BOX_PLUS]
                pixel_count = cv2.countNonZero(roi_mask)
                total_pixels = (y2 - y1) * (x2 - x1)
                ratio = pixel_count / total_pixels if total_pixels > 0 else 0
                on_path = (ratio > INTRUSION_THRESHOLD)
                # :ë„·: ê¹Šì´ ê³„ì‚° (ì¤‘ì•™ ROI í‰ê· )
                depth_val = None
                if depth_img is not None:
                    roi_size = 8
                    x_start = max(cx - roi_size , 0)
                    x_end = min(cx + roi_size, depth_img.shape[1])
                    y_start = max(cy - roi_size, 0)
                    y_end = min(cy + roi_size, depth_img.shape[0])
                    depth_roi = depth_img[y_start:y_end, x_start:x_end]
                    valid = depth_roi[np.isfinite(depth_roi) & (depth_roi > 0)]
                    if valid.size > 0:
                        depth_val = np.mean(valid) / 1000.0  # mm -> m
                # :ë‹¤ì„¯: 3D ì¢Œí‘œ ë³€í™˜ ë° ë¡œê·¸
                if depth_val is not None:
                    z = depth_val
                    x = (cx - self.cx) * z / self.fx
                    y = (cy - self.cy) * z / self.fy


                    # 2ï¸âƒ£ TF ë³€í™˜: base_link ê¸°ì¤€ ìƒëŒ€ ì¢Œí‘œ ê³„ì‚°
                    pt_camera = PointStamped()
                    pt_camera.header.frame_id = self.camera_frame_id  # ì˜ˆ: 'oakd_rgb_camera_frame'
                    pt_camera.header.stamp = rclpy.time.Time().to_msg()  # ë˜ëŠ” rgb_msg.header.stamp
                    pt_camera.point.x = x
                    pt_camera.point.y = y
                    pt_camera.point.z = z


                    # âœ… ì´ ì•„ëž˜ì— ì¶”ê°€
                    try:
                        pt_map = self.tf_buffer.transform(
                            pt_camera, 'map', timeout=rclpy.duration.Duration(seconds=0.5)
                        )
                        map_x = pt_map.point.x
                        map_y = pt_map.point.y
                        map_z = pt_map.point.z
                        self.get_logger().info(
                            f"ðŸ—ºï¸ [map ê¸°ì¤€] x={map_x:.2f}m, y={map_y:.2f}m, z={map_z:.2f}m"
                        )
                        
                        # âœ… RViz ë§ˆì»¤ ë°œí–‰
                        self.publish_marker(map_x, map_y, map_z)
                    
                       
                    except Exception as e:
                        self.get_logger().warn(f"[TF] map ê¸°ì¤€ ë³€í™˜ ì‹¤íŒ¨: {e}")

                # :ì—¬ì„¯: ì¹¨ë²” ì‹œ ê²½ê³  ë¡œê·¸
                if on_path:
                    self.get_logger().warn(":ê²½ê´‘ë“±: ë¶ˆë²• ì°¨ëŸ‰ í™•ì¸!")
                     # âœ… 1ï¸âƒ£ í¼ë¸”ë¦¬ì‹œ: ì¢Œí‘œë¥¼ PointStampedë¡œ í¼ë¸”ë¦¬ì‹œ
                    coord_msg = PointStamped()
                    coord_msg.header.stamp = self.get_clock().now().to_msg()
                    coord_msg.header.frame_id = 'map'
                    coord_msg.point.x = map_x
                    coord_msg.point.y = map_y
                    coord_msg.point.z = map_z
                    self.coord_pub.publish(coord_msg)

                # :ì¼ê³±: ì‹œê°í™”: ë°•ìŠ¤, ë¼ë²¨, ì¹¨ë²” ì—¬ë¶€ í‘œì‹œ
                box_color = (0, 0, 255) if on_path else (255, 255, 255)
                text = f"{label} {conf:.2f}" + (", illegal" if on_path else "")
                if depth_val is not None:
                    text += f" {depth_val:.2f}m"
                cv2.rectangle(rgb_img, (x1, y1), (x2, y2), box_color, 2)
                cv2.putText(rgb_img, text, (x1, y1 - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, box_color, 2)
                object_count += 1
        # ê°ì²´ ê°œìˆ˜ í‘œì‹œ
        cv2.putText(rgb_img, f"Objects: {object_count}", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
        # :ì—¬ëŸ: ê¹Šì´ ì˜ìƒ ì»¬ëŸ¬ë§µ ì‹œê°í™”
        if depth_img is not None:
            vis_depth = np.nan_to_num(depth_img, nan=0.0)
            vis_depth[vis_depth < 300] = 0
            vis_depth = np.clip(vis_depth, 0, NORMALIZE_DEPTH_RANGE * 1000)
            vis_depth_norm = (vis_depth / (NORMALIZE_DEPTH_RANGE * 1000) * 255).astype(np.uint8)
            depth_colored = cv2.applyColorMap(vis_depth_norm, cv2.COLORMAP_JET)
            combined = np.hstack((rgb_img, depth_colored))
            cv2.imshow("YOLO+Depth+GreenMask", combined)
        else:
            cv2.imshow("YOLO+Depth+GreenMask", rgb_img)


def ros_spin_thread(node):
    executor = MultiThreadedExecutor()
    executor.add_node(node)
    try:
        executor.spin()
    finally:
        node.destroy_node()


def main():
    rclpy.init()
    node = YoloDepthGreenDetector()  # ë˜ëŠ” YoloDepthViewer ì¤‘ í•˜ë‚˜ë§Œ ì‚¬ìš©
    ros_thread = threading.Thread(target=ros_spin_thread, args=(node,), daemon=True)
    ros_thread.start()
    try:
        while rclpy.ok() and not node.should_shutdown:
            node.process_and_show()
            if cv2.waitKey(1) & 0xFF == ord('q'):
                node.should_shutdown = True
                node.get_logger().info("Q ëˆŒëŸ¬ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
    except KeyboardInterrupt:
        node.get_logger().info("í‚¤ë³´ë“œ ì¸í„°ëŸ½íŠ¸ë¡œ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    finally:
        cv2.destroyAllWindows()
        rclpy.shutdown()
        ros_thread.join()
if __name__ == '__main__':
    main()
